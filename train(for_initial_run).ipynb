{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Code is not main training code\n",
    "## Use train.py to run for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "from data import set_up_data\n",
    "from utils import get_cpu_stats_over_ranks, logger\n",
    "from train_helpers import set_up_hyperparams, load_vaes, load_opt, accumulate_stats, save_model, update_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def training_step(H, data_input, target, vae, ema_vae, optimizer, iterate):\n",
    "    t0 = time.time()\n",
    "    vae.zero_grad()\n",
    "    stats = vae.forward(data_input, target)\n",
    "    stats['elbo'].backward()\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(vae.parameters(), H.grad_clip).item()\n",
    "    distortion_nans = torch.isnan(stats['distortion']).sum()\n",
    "    rate_nans = torch.isnan(stats['rate']).sum()\n",
    "    stats.update(dict(rate_nans=0 if rate_nans == 0 else 1, distortion_nans=0 if distortion_nans == 0 else 1))\n",
    "    stats = get_cpu_stats_over_ranks(stats)\n",
    "\n",
    "    skipped_updates = 1\n",
    "    # only update if no rank has a nan and if the grad norm is below a specific threshold\n",
    "    if stats['distortion_nans'] == 0 and stats['rate_nans'] == 0 and (H.skip_threshold == -1 or grad_norm < H.skip_threshold):\n",
    "        optimizer.step()\n",
    "        skipped_updates = 0\n",
    "        update_ema(vae, ema_vae, H.ema_rate)\n",
    "\n",
    "    t1 = time.time()\n",
    "    stats.update(skipped_updates=skipped_updates, iter_time=t1 - t0, grad_norm=grad_norm)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def eval_step(data_input, target, ema_vae):\n",
    "    with torch.no_grad():\n",
    "        stats = ema_vae.forward(data_input, target)\n",
    "    stats = get_cpu_stats_over_ranks(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_for_visualization(data, preprocess_fn, num, dataset):\n",
    "    for x in DataLoader(data, batch_size=num):\n",
    "        break\n",
    "    orig_image = x[0]\n",
    "    preprocessed = preprocess_fn(x)[0]\n",
    "    return orig_image, preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# add checkpoint load and save\n",
    "def train_loop(H, data_train, data_valid, preprocess_fn, vae, ema_vae, logprint):\n",
    "    import json  # For saving loss values to a file\n",
    "\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer, scheduler, cur_eval_loss, iterate, starting_epoch = load_opt(H, vae, logprint)\n",
    "    viz_batch_original, viz_batch_processed = get_sample_for_visualization(data_valid, preprocess_fn, H.num_images_visualize, H.dataset)\n",
    "    early_evals = set([1] + [2 ** exp for exp in range(3, 14)])\n",
    "    stats = []\n",
    "    iters_since_starting = 0\n",
    "    H.ema_rate = torch.as_tensor(H.ema_rate).cuda()\n",
    "\n",
    "    # Define checkpoint paths\n",
    "    checkpoint_path = os.path.join(H.save_dir, 'checkpoint.pth')\n",
    "    best_checkpoint_path = os.path.join(H.save_dir, 'best_checkpoint.pth')\n",
    "    loss_file_path = os.path.join(H.save_dir, 'loss_history.json')  # Path to save the losses\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    epoch, iterate = load_checkpoint(checkpoint_path, vae, ema_vae, optimizer, H)\n",
    "\n",
    "    # Track the best validation loss or metric\n",
    "    best_eval_loss = float('inf')\n",
    "\n",
    "    # Initialize loss history\n",
    "    loss_history = {\"train_loss\": [], \"eval_loss\": []}\n",
    "    if os.path.exists(loss_file_path):\n",
    "        with open(loss_file_path, \"r\") as f:\n",
    "            loss_history = json.load(f)\n",
    "\n",
    "    for epoch in range(epoch, H.num_epochs):\n",
    "        train_loader = DataLoader(\n",
    "            data_train,\n",
    "            batch_size=H.n_batch,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Wrap the training loop with tqdm\n",
    "        train_losses = []  # Track training loss for the epoch\n",
    "        for x in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\", unit=\"batch\"):\n",
    "            data_input, target = preprocess_fn(x)\n",
    "            training_stats = training_step(H, data_input, target, vae, ema_vae, optimizer, iterate)\n",
    "            train_losses.append(training_stats['elbo'])  \n",
    "            stats.append(training_stats)\n",
    "\n",
    "            scheduler.step()\n",
    "            if iterate % H.iters_per_print == 0 or iters_since_starting in early_evals:\n",
    "                logprint(model=H.desc, type='train_loss', lr=scheduler.get_last_lr()[0], epoch=epoch, step=iterate, **accumulate_stats(stats, H.iters_per_print))\n",
    "\n",
    "            if iterate % H.iters_per_images == 0 or (iters_since_starting in early_evals and H.dataset != 'ffhq_1024') and H.rank == 0:\n",
    "                write_images(H, ema_vae, viz_batch_original, viz_batch_processed, f'{H.save_dir}/samples-{iterate}.png', logprint)\n",
    "\n",
    "            iterate += 1\n",
    "            iters_since_starting += 1\n",
    "\n",
    "            if iterate % H.iters_per_save == 0 and H.rank == 0:\n",
    "                if np.isfinite(stats[-1]['elbo']):\n",
    "                    logprint(model=H.desc, type='train_loss', epoch=epoch, step=iterate, **accumulate_stats(stats, H.iters_per_print))\n",
    "                    fp = os.path.join(H.save_dir, 'latest')\n",
    "                    logprint(f'Saving model@ {iterate} to {fp}')\n",
    "                    save_model(fp, vae, ema_vae, optimizer, H)\n",
    "\n",
    "            if iterate % H.iters_per_ckpt == 0 and H.rank == 0:\n",
    "                save_model(os.path.join(H.save_dir, f'iter-{iterate}'), vae, ema_vae, optimizer, H)\n",
    "\n",
    "        # Save average training loss for the epoch\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        loss_history[\"train_loss\"].append(avg_train_loss)\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        if epoch % H.epochs_per_eval == 0:\n",
    "            valid_stats = evaluate(H, ema_vae, data_valid, preprocess_fn)\n",
    "            eval_loss = valid_stats['filtered_elbo']  # Use the relevant validation metric\n",
    "            loss_history[\"eval_loss\"].append(eval_loss)\n",
    "            logprint(model=H.desc, type='eval_loss', epoch=epoch, step=iterate, **valid_stats)\n",
    "\n",
    "            # Compare with the best evaluation loss\n",
    "            if eval_loss < best_eval_loss:\n",
    "                best_eval_loss = eval_loss\n",
    "                save_checkpoint(epoch + 1, vae, ema_vae, optimizer, H, iterate, best_checkpoint_path)\n",
    "                logprint(f\"New best model found with eval loss {best_eval_loss:.4f}. Checkpoint saved to {best_checkpoint_path}\")\n",
    "\n",
    "        # Save a general checkpoint after each epoch\n",
    "        save_checkpoint(epoch + 1, vae, ema_vae, optimizer, H, iterate, checkpoint_path)\n",
    "        logprint(f\"Epoch {epoch + 1} completed. General checkpoint saved to {checkpoint_path}.\")\n",
    "\n",
    "        # Save the loss history to a file\n",
    "        with open(loss_file_path, \"w\") as f:\n",
    "            json.dump(loss_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(H, ema_vae, data_valid, preprocess_fn):\n",
    "    stats_valid = []\n",
    "    data_loader = DataLoader(data_valid, \n",
    "                             batch_size=H.n_batch, \n",
    "                             drop_last=True, \n",
    "                             pin_memory=True, \n",
    "                             shuffle=True) \n",
    "\n",
    "    # for x in data_loader:\n",
    "    # Wrap the evaluation loop with tqdm\n",
    "    for x in tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        data_input, target = preprocess_fn(x)\n",
    "        stats_valid.append(eval_step(data_input, target, ema_vae))\n",
    "    vals = [a['elbo'] for a in stats_valid]\n",
    "    finites = np.array(vals)[np.isfinite(vals)]\n",
    "    stats = dict(\n",
    "        n_batches=len(vals),\n",
    "        filtered_elbo=np.mean(finites),\n",
    "        **{k: np.mean([a[k] for a in stats_valid]) for k in stats_valid[-1]}\n",
    "    )\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def write_images(H, ema_vae, viz_batch_original, viz_batch_processed, fname, logprint):\n",
    "    zs = [s['z'].cuda() for s in ema_vae.forward_get_latents(viz_batch_processed)]\n",
    "    batches = [viz_batch_original.numpy()]\n",
    "    mb = viz_batch_processed.shape[0]\n",
    "    lv_points = np.floor(np.linspace(0, 1, H.num_variables_visualize + 2) * len(zs)).astype(int)[1:-1]\n",
    "    for i in lv_points:\n",
    "        batches.append(ema_vae.forward_samples_set_latents(mb, zs[:i], t=0.1))\n",
    "    for t in [1.0, 0.9, 0.8, 0.7][:H.num_temperatures_visualize]:\n",
    "        batches.append(ema_vae.forward_uncond_samples(mb, t=t))\n",
    "    n_rows = len(batches)\n",
    "    im = np.concatenate(batches, axis=0).reshape((n_rows, mb, *viz_batch_processed.shape[1:])).transpose([0, 2, 1, 3, 4]).reshape([n_rows * viz_batch_processed.shape[1], mb * viz_batch_processed.shape[2], 3])\n",
    "    logprint(f'printing samples to {fname}')\n",
    "    imageio.imwrite(fname, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_test_eval(H, ema_vae, data_test, preprocess_fn, logprint):\n",
    "    print('evaluating')\n",
    "    stats = evaluate(H, ema_vae, data_test, preprocess_fn)\n",
    "    print('test results')\n",
    "    for k in stats:\n",
    "        print(k, stats[k])\n",
    "    logprint(type='test_loss', **stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# add checkpoint function for long train\n",
    "def save_checkpoint(epoch, vae, ema_vae, optimizer, H, iterate, checkpoint_path):\n",
    "    \"\"\"Save a training checkpoint.\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'iterate': iterate,\n",
    "        'model_state_dict': vae.state_dict(),\n",
    "        'ema_model_state_dict': ema_vae.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'H': vars(H)  # Save the hyperparameters\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(checkpoint_path, vae, ema_vae, optimizer, H):\n",
    "    \"\"\"Load a training checkpoint.\"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "        vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        ema_vae.load_state_dict(checkpoint['ema_model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        H.__dict__.update(checkpoint['H'])  # Restore hyperparameters\n",
    "        print(f\"Checkpoint loaded from {checkpoint_path}\")\n",
    "        return checkpoint['epoch'], checkpoint['iterate']\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {checkpoint_path}. Starting fresh.\")\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate the command-line arguments\n",
    "args = [\n",
    "    '--hps', 'cifar10',  # Hyperparameter set\n",
    "    '--save_dir', './saved_models',  # Directory to save models\n",
    "    '--data_root', '.',  # Root directory for the dataset\n",
    "    '--desc', 'cifar10_training',  # Description of the run\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# H, logprint = set_up_hyperparams()\n",
    "H, logprint = set_up_hyperparams(args)\n",
    "# print(\"data_root = \", H.data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "H, data_train, data_valid_or_test, preprocess_fn = set_up_data(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vae, ema_vae = load_vaes(H, logprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if H.test_eval:\n",
    "    # Run evaluation if test_eval is True\n",
    "    run_test_eval(H, ema_vae, data_valid_or_test, preprocess_fn, logprint)\n",
    "else:\n",
    "    # Run the training loop otherwise\n",
    "    train_loop(H, data_train, data_valid_or_test, preprocess_fn, vae, ema_vae, logprint)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
